{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -2.466987\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** The loss is equal to approximately -log(probability). Because there are 10 total classes, the probability that a random guesser correctly predicts an image is 1/10, or 0.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.838490 analytic: 0.838490, relative error: 1.407484e-08\n",
      "numerical: -1.041059 analytic: -1.041059, relative error: 8.979335e-09\n",
      "numerical: -1.420837 analytic: -1.420837, relative error: 2.413466e-08\n",
      "numerical: 1.913122 analytic: 1.913122, relative error: 5.889929e-08\n",
      "numerical: -1.323568 analytic: -1.323568, relative error: 2.969759e-08\n",
      "numerical: -0.729494 analytic: -0.729494, relative error: 1.208241e-08\n",
      "numerical: 2.216259 analytic: 2.216259, relative error: 2.483090e-09\n",
      "numerical: 0.833948 analytic: 0.833947, relative error: 2.077128e-08\n",
      "numerical: -0.118165 analytic: -0.118165, relative error: 5.937400e-07\n",
      "numerical: 0.527339 analytic: 0.527339, relative error: 2.959274e-08\n",
      "numerical: -0.446960 analytic: -0.446960, relative error: 8.916356e-08\n",
      "numerical: 3.103209 analytic: 3.103209, relative error: 1.055835e-08\n",
      "numerical: 0.279332 analytic: 0.279332, relative error: 9.938720e-08\n",
      "numerical: -0.345057 analytic: -0.345057, relative error: 2.184491e-08\n",
      "numerical: -0.689896 analytic: -0.689896, relative error: 1.493884e-08\n",
      "numerical: 1.243610 analytic: 1.243610, relative error: 3.204913e-09\n",
      "numerical: -1.623200 analytic: -1.623200, relative error: 2.350214e-08\n",
      "numerical: -6.724507 analytic: -6.724507, relative error: 6.472986e-09\n",
      "numerical: 0.115988 analytic: 0.115988, relative error: 5.183538e-07\n",
      "numerical: 1.877396 analytic: 1.877396, relative error: 6.970096e-09\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.342508e+00 computed in 0.096424s\n",
      "vectorized loss: 2.342508e+00 computed in 0.004362s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1e-08, reg: 0.01.\n",
      "training_acc: 0.13089795918367347, valid_acc: 0.126\n",
      "learning rate: 1e-08, reg: 0.05994842503189409.\n",
      "training_acc: 0.12120408163265306, valid_acc: 0.091\n",
      "learning rate: 1e-08, reg: 0.35938136638046275.\n",
      "training_acc: 0.133, valid_acc: 0.129\n",
      "learning rate: 1e-08, reg: 2.1544346900318843.\n",
      "training_acc: 0.13453061224489796, valid_acc: 0.128\n",
      "learning rate: 1e-08, reg: 12.91549665014884.\n",
      "training_acc: 0.11597959183673469, valid_acc: 0.136\n",
      "learning rate: 1e-08, reg: 77.4263682681127.\n",
      "training_acc: 0.10793877551020409, valid_acc: 0.105\n",
      "learning rate: 1e-08, reg: 464.1588833612782.\n",
      "training_acc: 0.1306734693877551, valid_acc: 0.129\n",
      "learning rate: 1e-08, reg: 2782.559402207126.\n",
      "training_acc: 0.11059183673469387, valid_acc: 0.126\n",
      "learning rate: 1e-08, reg: 16681.005372000593.\n",
      "training_acc: 0.1386734693877551, valid_acc: 0.118\n",
      "learning rate: 1e-08, reg: 100000.0.\n",
      "training_acc: 0.11022448979591837, valid_acc: 0.113\n",
      "learning rate: 1e-07, reg: 0.01.\n",
      "training_acc: 0.21151020408163265, valid_acc: 0.208\n",
      "learning rate: 1e-07, reg: 0.05994842503189409.\n",
      "training_acc: 0.20577551020408164, valid_acc: 0.193\n",
      "learning rate: 1e-07, reg: 0.35938136638046275.\n",
      "training_acc: 0.19757142857142856, valid_acc: 0.192\n",
      "learning rate: 1e-07, reg: 2.1544346900318843.\n",
      "training_acc: 0.19120408163265307, valid_acc: 0.195\n",
      "learning rate: 1e-07, reg: 12.91549665014884.\n",
      "training_acc: 0.21157142857142858, valid_acc: 0.2\n",
      "learning rate: 1e-07, reg: 77.4263682681127.\n",
      "training_acc: 0.19938775510204082, valid_acc: 0.21\n",
      "learning rate: 1e-07, reg: 464.1588833612782.\n",
      "training_acc: 0.19748979591836735, valid_acc: 0.213\n",
      "learning rate: 1e-07, reg: 2782.559402207126.\n",
      "training_acc: 0.2076326530612245, valid_acc: 0.209\n",
      "learning rate: 1e-07, reg: 16681.005372000593.\n",
      "training_acc: 0.23885714285714285, valid_acc: 0.258\n",
      "learning rate: 1e-07, reg: 100000.0.\n",
      "training_acc: 0.3077755102040816, valid_acc: 0.32\n",
      "learning rate: 1e-06, reg: 0.01.\n",
      "training_acc: 0.3006938775510204, valid_acc: 0.309\n",
      "learning rate: 1e-06, reg: 0.05994842503189409.\n",
      "training_acc: 0.2910204081632653, valid_acc: 0.31\n",
      "learning rate: 1e-06, reg: 0.35938136638046275.\n",
      "training_acc: 0.30028571428571427, valid_acc: 0.306\n",
      "learning rate: 1e-06, reg: 2.1544346900318843.\n",
      "training_acc: 0.297, valid_acc: 0.298\n",
      "learning rate: 1e-06, reg: 12.91549665014884.\n",
      "training_acc: 0.29522448979591837, valid_acc: 0.303\n",
      "learning rate: 1e-06, reg: 77.4263682681127.\n",
      "training_acc: 0.3031632653061225, valid_acc: 0.316\n",
      "learning rate: 1e-06, reg: 464.1588833612782.\n",
      "training_acc: 0.3136122448979592, valid_acc: 0.32\n",
      "learning rate: 1e-06, reg: 2782.559402207126.\n",
      "training_acc: 0.3715510204081633, valid_acc: 0.371\n",
      "learning rate: 1e-06, reg: 16681.005372000593.\n",
      "training_acc: 0.3527142857142857, valid_acc: 0.367\n",
      "learning rate: 1e-06, reg: 100000.0.\n",
      "training_acc: 0.2966938775510204, valid_acc: 0.313\n",
      "learning rate: 1e-05, reg: 0.01.\n",
      "training_acc: 0.32463265306122446, valid_acc: 0.298\n",
      "learning rate: 1e-05, reg: 0.05994842503189409.\n",
      "training_acc: 0.29020408163265304, valid_acc: 0.295\n",
      "learning rate: 1e-05, reg: 0.35938136638046275.\n",
      "training_acc: 0.2906938775510204, valid_acc: 0.275\n",
      "learning rate: 1e-05, reg: 2.1544346900318843.\n",
      "training_acc: 0.3089183673469388, valid_acc: 0.334\n",
      "learning rate: 1e-05, reg: 12.91549665014884.\n",
      "training_acc: 0.3323061224489796, valid_acc: 0.327\n",
      "learning rate: 1e-05, reg: 77.4263682681127.\n",
      "training_acc: 0.34555102040816327, valid_acc: 0.319\n",
      "learning rate: 1e-05, reg: 464.1588833612782.\n",
      "training_acc: 0.3213673469387755, valid_acc: 0.312\n",
      "learning rate: 1e-05, reg: 2782.559402207126.\n",
      "training_acc: 0.2908775510204082, valid_acc: 0.286\n",
      "learning rate: 1e-05, reg: 16681.005372000593.\n",
      "training_acc: 0.14755102040816326, valid_acc: 0.174\n",
      "learning rate: 1e-05, reg: 100000.0.\n",
      "training_acc: 0.08916326530612245, valid_acc: 0.093\n",
      "learning rate: 0.0001, reg: 0.01.\n",
      "training_acc: 0.2850204081632653, valid_acc: 0.276\n",
      "learning rate: 0.0001, reg: 0.05994842503189409.\n",
      "training_acc: 0.3000204081632653, valid_acc: 0.286\n",
      "learning rate: 0.0001, reg: 0.35938136638046275.\n",
      "training_acc: 0.2950816326530612, valid_acc: 0.284\n",
      "learning rate: 0.0001, reg: 2.1544346900318843.\n",
      "training_acc: 0.26622448979591834, valid_acc: 0.255\n",
      "learning rate: 0.0001, reg: 12.91549665014884.\n",
      "training_acc: 0.25387755102040815, valid_acc: 0.259\n",
      "learning rate: 0.0001, reg: 77.4263682681127.\n",
      "training_acc: 0.25342857142857145, valid_acc: 0.255\n",
      "learning rate: 0.0001, reg: 464.1588833612782.\n",
      "training_acc: 0.21981632653061225, valid_acc: 0.235\n",
      "learning rate: 0.0001, reg: 2782.559402207126.\n",
      "training_acc: 0.14679591836734693, valid_acc: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kfang/Desktop/CS4/linear/cs231n/classifiers/softmax.py:89: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = np.sum(-np.log(correct_probs)) / num_train\n",
      "/Users/kfang/Desktop/CS4/linear/cs231n/classifiers/softmax.py:85: RuntimeWarning: overflow encountered in exp\n",
      "  probs = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
      "/Users/kfang/Desktop/CS4/linear/cs231n/classifiers/softmax.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probs = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.0001, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.0001, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 0.01.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 0.05994842503189409.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 0.35938136638046275.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 2.1544346900318843.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 12.91549665014884.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 77.4263682681127.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 464.1588833612782.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 2782.559402207126.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.001, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 0.01.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 0.05994842503189409.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 0.35938136638046275.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 2.1544346900318843.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 12.91549665014884.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 77.4263682681127.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 464.1588833612782.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 2782.559402207126.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.01, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 0.01.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 0.05994842503189409.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 0.35938136638046275.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 2.1544346900318843.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 12.91549665014884.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 77.4263682681127.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 464.1588833612782.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 2782.559402207126.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 0.1, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 0.01.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 0.05994842503189409.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 0.35938136638046275.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 2.1544346900318843.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 12.91549665014884.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 77.4263682681127.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 464.1588833612782.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 2782.559402207126.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 1.0, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 0.01.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 0.05994842503189409.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 0.35938136638046275.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 2.1544346900318843.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 12.91549665014884.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 77.4263682681127.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 464.1588833612782.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 2782.559402207126.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 16681.005372000593.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "learning rate: 10.0, reg: 100000.0.\n",
      "training_acc: 0.10026530612244898, valid_acc: 0.087\n",
      "lr 1.000000e-08 reg 1.000000e-02 train accuracy: 0.130898 val accuracy: 0.126000\n",
      "lr 1.000000e-08 reg 5.994843e-02 train accuracy: 0.121204 val accuracy: 0.091000\n",
      "lr 1.000000e-08 reg 3.593814e-01 train accuracy: 0.133000 val accuracy: 0.129000\n",
      "lr 1.000000e-08 reg 2.154435e+00 train accuracy: 0.134531 val accuracy: 0.128000\n",
      "lr 1.000000e-08 reg 1.291550e+01 train accuracy: 0.115980 val accuracy: 0.136000\n",
      "lr 1.000000e-08 reg 7.742637e+01 train accuracy: 0.107939 val accuracy: 0.105000\n",
      "lr 1.000000e-08 reg 4.641589e+02 train accuracy: 0.130673 val accuracy: 0.129000\n",
      "lr 1.000000e-08 reg 2.782559e+03 train accuracy: 0.110592 val accuracy: 0.126000\n",
      "lr 1.000000e-08 reg 1.668101e+04 train accuracy: 0.138673 val accuracy: 0.118000\n",
      "lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.110224 val accuracy: 0.113000\n",
      "lr 1.000000e-07 reg 1.000000e-02 train accuracy: 0.211510 val accuracy: 0.208000\n",
      "lr 1.000000e-07 reg 5.994843e-02 train accuracy: 0.205776 val accuracy: 0.193000\n",
      "lr 1.000000e-07 reg 3.593814e-01 train accuracy: 0.197571 val accuracy: 0.192000\n",
      "lr 1.000000e-07 reg 2.154435e+00 train accuracy: 0.191204 val accuracy: 0.195000\n",
      "lr 1.000000e-07 reg 1.291550e+01 train accuracy: 0.211571 val accuracy: 0.200000\n",
      "lr 1.000000e-07 reg 7.742637e+01 train accuracy: 0.199388 val accuracy: 0.210000\n",
      "lr 1.000000e-07 reg 4.641589e+02 train accuracy: 0.197490 val accuracy: 0.213000\n",
      "lr 1.000000e-07 reg 2.782559e+03 train accuracy: 0.207633 val accuracy: 0.209000\n",
      "lr 1.000000e-07 reg 1.668101e+04 train accuracy: 0.238857 val accuracy: 0.258000\n",
      "lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.307776 val accuracy: 0.320000\n",
      "lr 1.000000e-06 reg 1.000000e-02 train accuracy: 0.300694 val accuracy: 0.309000\n",
      "lr 1.000000e-06 reg 5.994843e-02 train accuracy: 0.291020 val accuracy: 0.310000\n",
      "lr 1.000000e-06 reg 3.593814e-01 train accuracy: 0.300286 val accuracy: 0.306000\n",
      "lr 1.000000e-06 reg 2.154435e+00 train accuracy: 0.297000 val accuracy: 0.298000\n",
      "lr 1.000000e-06 reg 1.291550e+01 train accuracy: 0.295224 val accuracy: 0.303000\n",
      "lr 1.000000e-06 reg 7.742637e+01 train accuracy: 0.303163 val accuracy: 0.316000\n",
      "lr 1.000000e-06 reg 4.641589e+02 train accuracy: 0.313612 val accuracy: 0.320000\n",
      "lr 1.000000e-06 reg 2.782559e+03 train accuracy: 0.371551 val accuracy: 0.371000\n",
      "lr 1.000000e-06 reg 1.668101e+04 train accuracy: 0.352714 val accuracy: 0.367000\n",
      "lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.296694 val accuracy: 0.313000\n",
      "lr 1.000000e-05 reg 1.000000e-02 train accuracy: 0.324633 val accuracy: 0.298000\n",
      "lr 1.000000e-05 reg 5.994843e-02 train accuracy: 0.290204 val accuracy: 0.295000\n",
      "lr 1.000000e-05 reg 3.593814e-01 train accuracy: 0.290694 val accuracy: 0.275000\n",
      "lr 1.000000e-05 reg 2.154435e+00 train accuracy: 0.308918 val accuracy: 0.334000\n",
      "lr 1.000000e-05 reg 1.291550e+01 train accuracy: 0.332306 val accuracy: 0.327000\n",
      "lr 1.000000e-05 reg 7.742637e+01 train accuracy: 0.345551 val accuracy: 0.319000\n",
      "lr 1.000000e-05 reg 4.641589e+02 train accuracy: 0.321367 val accuracy: 0.312000\n",
      "lr 1.000000e-05 reg 2.782559e+03 train accuracy: 0.290878 val accuracy: 0.286000\n",
      "lr 1.000000e-05 reg 1.668101e+04 train accuracy: 0.147551 val accuracy: 0.174000\n",
      "lr 1.000000e-05 reg 1.000000e+05 train accuracy: 0.089163 val accuracy: 0.093000\n",
      "lr 1.000000e-04 reg 1.000000e-02 train accuracy: 0.285020 val accuracy: 0.276000\n",
      "lr 1.000000e-04 reg 5.994843e-02 train accuracy: 0.300020 val accuracy: 0.286000\n",
      "lr 1.000000e-04 reg 3.593814e-01 train accuracy: 0.295082 val accuracy: 0.284000\n",
      "lr 1.000000e-04 reg 2.154435e+00 train accuracy: 0.266224 val accuracy: 0.255000\n",
      "lr 1.000000e-04 reg 1.291550e+01 train accuracy: 0.253878 val accuracy: 0.259000\n",
      "lr 1.000000e-04 reg 7.742637e+01 train accuracy: 0.253429 val accuracy: 0.255000\n",
      "lr 1.000000e-04 reg 4.641589e+02 train accuracy: 0.219816 val accuracy: 0.235000\n",
      "lr 1.000000e-04 reg 2.782559e+03 train accuracy: 0.146796 val accuracy: 0.160000\n",
      "lr 1.000000e-04 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-04 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.000000e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 5.994843e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 3.593814e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.154435e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.291550e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 7.742637e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 4.641589e+02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 2.782559e+03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-03 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 1.000000e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 5.994843e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 3.593814e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 2.154435e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 1.291550e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 7.742637e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 4.641589e+02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 2.782559e+03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-02 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.000000e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 5.994843e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 3.593814e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.154435e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.291550e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 7.742637e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 4.641589e+02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 2.782559e+03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e-01 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 1.000000e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 5.994843e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 3.593814e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 2.154435e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 1.291550e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 7.742637e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 4.641589e+02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 2.782559e+03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+00 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.000000e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 5.994843e-02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 3.593814e-01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.154435e+00 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.291550e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 7.742637e+01 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 4.641589e+02 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 2.782559e+03 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.668101e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 1.000000e+01 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "best validation accuracy achieved during cross-validation: 0.371000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "iters = 500\n",
    "# loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4, num_iters=1500, verbose=True)\n",
    "learning_rate_range = np.logspace(-8, 1, 10)\n",
    "reg_range = np.logspace(-2, 5, 10)\n",
    "\n",
    "for learning_rate in learning_rate_range:\n",
    "    for reg in reg_range:\n",
    "        softmax_test = Softmax()\n",
    "        loss_hist = softmax_test.train(X_train, y_train, learning_rate = learning_rate, reg = reg, num_iters = iters, verbose=False)\n",
    "        #print(\"Learning rate: {}; reg: {}; loss: {}\".format(learning_rate, reg, loss_hist[-1]))\n",
    "        \n",
    "        y_train_pred = softmax_test.predict(X_train)\n",
    "        training_accuracy = np.mean(y_train == y_train_pred)\n",
    "        \n",
    "        y_val_pred = softmax_test.predict(X_val)\n",
    "        validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(learning_rate, reg)] = (training_accuracy, validation_accuracy)\n",
    "        \n",
    "        if validation_accuracy > best_val:\n",
    "            best_val = validation_accuracy\n",
    "            best_softmax = softmax_test\n",
    "        \n",
    "        print(\"learning rate: {}, reg: {}.\\ntraining_acc: {}, valid_acc: {}\".format(learning_rate, reg, training_accuracy, validation_accuracy))\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.367000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 2000: loss 261.013040\n",
      "iteration 200 / 2000: loss 10.688400\n",
      "iteration 300 / 2000: loss 2.312630\n",
      "iteration 400 / 2000: loss 1.967775\n",
      "iteration 500 / 2000: loss 2.033503\n",
      "iteration 600 / 2000: loss 2.054055\n",
      "iteration 700 / 2000: loss 1.985848\n",
      "iteration 800 / 2000: loss 1.967599\n",
      "iteration 900 / 2000: loss 1.961006\n",
      "iteration 1000 / 2000: loss 1.945671\n",
      "iteration 1100 / 2000: loss 2.022966\n",
      "iteration 1200 / 2000: loss 2.080688\n",
      "iteration 1300 / 2000: loss 2.013340\n",
      "iteration 1400 / 2000: loss 2.017384\n",
      "iteration 1500 / 2000: loss 2.005915\n",
      "iteration 1600 / 2000: loss 1.971927\n",
      "iteration 1700 / 2000: loss 1.979734\n",
      "iteration 1800 / 2000: loss 2.012324\n",
      "iteration 1900 / 2000: loss 2.017865\n",
      "iteration 2000 / 2000: loss 2.014774\n",
      "softmax on raw pixels final test set accuracy: 0.360000\n"
     ]
    }
   ],
   "source": [
    "# learning rate: 1e-06, reg: 16681.005372000593\n",
    "\n",
    "best_softmax = Softmax()\n",
    "loss_hist = best_softmax.train(X_train, y_train, learning_rate=1e-06, reg=16681, num_iters=2000, verbose=True)\n",
    "\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAgEAoEHEC9TgUAgEAgEAg/gvwElxqcVQC63uQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181a671080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
